d_in_neg_test  <- apply(A_test, 2, FUN=function(x) length(which(x[]==-1)))        # in-negative degree
d_out_pos_test <- apply(A_test, 1, FUN=function(x) length(which(x[]==1)))         # out-positive degree
d_out_neg_test <- apply(A_test, 1, FUN=function(x) length(which(x[]==-1)))        # out-negative degree
#----- Add variables to the datasets
training_edges$pos_in_degree    <- d_in_pos_train[training_edges$user]
training_edges$neg_in_degree    <- d_in_neg_train[training_edges$user]
training_edges$pos_out_degree   <- d_out_pos_train[training_edges$user]
training_edges$neg_out_degree   <- d_out_neg_train[training_edges$user]
test_edges$pos_in_degree    <- d_in_pos_test[test_edges$user]
test_edges$neg_in_degree    <- d_in_neg_test[test_edges$user]
test_edges$pos_out_degree   <- d_out_pos_test[test_edges$user]
test_edges$neg_out_degree   <- d_out_neg_test[test_edges$user]
#CHUNK 7: build the model and evaluate it on the test dataset.
# NA the the rows in which vote=0
training_edges[training_edges$vote == 0,] <- NA
test_edges[test_edges$vote == 0,] <- NA
# Change -1 for 0 in vote column in order to use glm
training_edges$vote[training_edges$vote == -1] <- 0
test_edges$vote[test_edges$vote == -1] <- 0
# Fit the model
logistic = glm(vote ~  pos_in_degree+ neg_in_degree + pos_out_degree + neg_out_degree + recomendation_degree , data = training_edges, family = binomial)
# Summarize the model
summary(logistic)
# Make predictions
probabilities <- predict(logistic, test_edges, type="response", family=binomial)
predicted_signs <- ifelse(probabilities > 0.5, 1, 0)
# Model accuracy
accuracy <- mean(na.omit(predicted_signs) == na.omit(test_edges)$vote)
accuracy
# load raw data files
votings<-read.table("votings.txt",sep=";",stringsAsFactors = F,header=F,quote="")
# setting headers
colnames(votings)<-c("voter","user","timestamp","vote")
head(votings)
#check_unique <- unique(votings)
# Load libraries
library(igraph)
library(Matrix)
# CHUNK 1: code to split the original datasets in two training_edges and test_edges
sample_size = floor(0.8*nrow(votings))  # Sample size (i.e. 80% of the number of rows in the dataset)
set.seed(123)                           # Set seed to have the same random numbers generated
training_id = sample(seq_len(nrow(votings)),size = sample_size)  # Choose randomly the rows equal to sample_size from all
# the rows of voting dataset and stores the row number                                                                    # in training_id
training_edges = votings[training_id,]   # Create the training dataset with row numbers stored in training_ind
test_edges     = votings[-training_id,]  # Create the test dataset excluding the row numbers mentioned in training_ind
# CHUNK 2: code to create these variables for the edges.
#------For training dataset
# Transform the dataset into an adjacency matrix
edge_train_list <- training_edges[,c(1,2,4)]                                      # Create the edge list without timestamp
G_train <- graph.data.frame(edge_train_list, directed=TRUE)                       # Create the graph
A_train <- as_adjacency_matrix(G_train, names=TRUE, sparse=TRUE, attr = "vote")   # Create the adjacency matrix
# Duda: ¿Cómo se tienen en cuenta los votos repetidos en la matriz de adyacencia? ¿Coge el último voto? ¿Suma los votos?
# Variables
d_in_pos_train  <- apply(A_train, 2, FUN=function(x) length(which(x[]==1)))    # in-positive degree
d_in_neg_train  <- apply(A_train, 2, FUN=function(x) length(which(x[]==-1)))   # in-negative degree
d_out_pos_train <- apply(A_train, 1, FUN=function(x) length(which(x[]==1)))    # out-positive degree
d_out_neg_train <- apply(A_train, 1, FUN=function(x) length(which(x[]==-1)))   # out-negative degree
total_pos_degree_train = d_in_pos_train + d_out_pos_train                      # Total positive degree
total_neg_degree_train = d_in_neg_train + d_out_neg_train                      # Total negative degree
#------For test dataset
# Transform the dataset into an adjacency matrix
edge_test_list <- test_edges[,c(1,2,4)]                                          # Create the edge list
G_test <- graph.data.frame(edge_test_list, directed=TRUE)                        # Create the graph
A_test <- as_adjacency_matrix(G_test, names=TRUE, sparse=TRUE, attr = "vote")    # Create the adjacency matrix
# Create variables
d_in_pos_test  <- apply(A_test, 2, FUN=function(x) length(which(x[]==1)))      # in-positive degree
d_in_neg_test  <- apply(A_test, 2, FUN=function(x) length(which(x[]==-1)))     # in-negative degree
d_out_pos_test <- apply(A_test, 1, FUN=function(x) length(which(x[]==1)))      # out-positive degree
d_out_neg_test <- apply(A_test, 1, FUN=function(x) length(which(x[]==-1)))     # out-negative degree
total_pos_degree_test = d_in_pos_test + d_out_pos_test                         # Total positive degree
total_neg_degree_test = d_in_neg_test + d_out_neg_test                         # Total negative degree
#----- Add variables to the datasets
training_edges$pos_in_degree    <- d_in_pos_train[training_edges$user]         # Match with user variable.
training_edges$neg_in_degree    <- d_in_neg_train[training_edges$user]
training_edges$pos_out_degree   <- d_out_pos_train[training_edges$user]
training_edges$neg_out_degree   <- d_out_neg_train[training_edges$user]
training_edges$total_pos_degree <- total_pos_degree_train[training_edges$user]
training_edges$total_neg_degree <- total_neg_degree_train[training_edges$user]
test_edges$pos_in_degree    <- d_in_pos_test[test_edges$user]
test_edges$neg_in_degree    <- d_in_neg_test[test_edges$user]
test_edges$pos_out_degree   <- d_out_pos_test[test_edges$user]
test_edges$neg_out_degree   <- d_out_neg_test[test_edges$user]
test_edges$total_pos_degree <- total_pos_degree_test[test_edges$user]
test_edges$total_neg_degree <- total_neg_degree_test[test_edges$user]
# Show heads of the datasets with the new variables
head(training_edges)
head(test_edges)
# CHUNK 3: code to create the regression model and evaluate it on the test.
# NA the the rows in which vote=0
training_edges[training_edges$vote == 0,] <- NA
test_edges[test_edges$vote == 0,] <- NA
# Change -1 for 0 in vote column in order to use glm
training_edges$vote[training_edges$vote == -1] <- 0
test_edges$vote[test_edges$vote == -1] <- 0
# Fit the model
logistic = glm(vote ~  pos_in_degree+ neg_in_degree + pos_out_degree + neg_out_degree , data = training_edges, family = binomial)
# Summarize the model
summary(logistic)
# Make predictions
probabilities   <- predict(logistic, test_edges, type="response", family=binomial)
predicted_signs <- ifelse(probabilities > 0.5, 1, 0)
# Model accuracy
accuracy <- mean(na.omit(predicted_signs) == na.omit(test_edges)$vote)
accuracy
# Entender por qué obtengo NA's en en predicted_signs -> Probabilities contiene NA's porque test_edges los tiene. Por tanto, predicted_signs tiene que contener NA's
# CHUNK 4: create the code and visualizations you consider to evaluate these 3 affirmations
votings0       <- votings[,c(1,2,4)]                                               # votings dataset without timestamp
votings0_graph <- graph.data.frame(votings0, directed=TRUE)                        # Create the graph
A <- as_adjacency_matrix(votings0_graph, names=TRUE, sparse=TRUE, attr = "vote")   # Create the adjacency matrix
A2 <- A %*% A                           # Adyacency matrix to the power two. It gives the preferred vote from u->v                                                # according to the vote that the friends and enemies of u have given to v.
C  <- A * 1 * ((sign(A) == sign(A2)))   # Multiply by 1 to transform TRUE->1 and FALSE->0. Element-wise multiplication                                            # (A*...) to set zero the 1's obtained because the sign of the correspondings 0's.
same_sign   = nnzero(C)                 # Count the numbers !=0
total_edges = nnzero(A)                 # Count the number of edges !=0 in the adyacency matrix
same_sign / total_edges
# CHUNK 5: create the new training and test datasets.
# Add the new variable "recomendation degree"
dataA2 <- as.data.frame(as.table(as.matrix(A2)))                  #Dataframe from the adyancency matrix to the power 2
colnames(dataA2) <- c("voter", "user", "recomendation_degree")    #Add names to the columns
dataA2$voter <- as.character(dataA2$voter)
dataA2$user <- as.character(dataA2$user)
newVotings <- merge(votings, dataA2 , by=c("voter","user"))       #Merge votings and dataA2 dataset by "voter" and "user"
# Sort dataset by timestamp and get samples
votings_ordered <- newVotings[order(as.Date(newVotings$timestamp)),]
sample_size = floor(0.8*nrow(votings_ordered))
set.seed(123)
training_id = sample(seq_len(nrow(votings_ordered)),size = sample_size)
training_edges = votings_ordered[training_id,]
test_edges     = votings_ordered[-training_id,]
# CHUNK 6: create the new variables based on the knowledge of how votes spread on the network
#------For training dataset
# Transform the dataset into an adjacency matrix
edge_train_list <- training_edges[,c(1,2,4)]                                      # Create the edge list
G_train <- graph.data.frame(edge_train_list, directed=TRUE)                       # Create the graph
A_train <- as_adjacency_matrix(G_train, names=TRUE, sparse=TRUE, attr = "vote")   # Create the adjacency matrix
# Variables
d_in_pos_train  <- apply(A_train, 2, FUN=function(x) length(which(x[]==1)))       # in-positive degree
d_in_neg_train  <- apply(A_train, 2, FUN=function(x) length(which(x[]==-1)))      # in-negative degree
d_out_pos_train <- apply(A_train, 1, FUN=function(x) length(which(x[]==1)))       # out-positive degree
d_out_neg_train <- apply(A_train, 1, FUN=function(x) length(which(x[]==-1)))      # out-negative degree
#------For test dataset
# Transform the dataset into an adjacency matrix
edge_test_list <- test_edges[,c(1,2,4)]                                           # create the edge list
G_test <- graph.data.frame(edge_test_list, directed=TRUE)                         # create the graph
A_test <- as_adjacency_matrix(G_test, names=TRUE, sparse=TRUE, attr = "vote")     # create the adjacency matrix
# Create variables
d_in_pos_test  <- apply(A_test, 2, FUN=function(x) length(which(x[]==1)))         # in-positive degree
d_in_neg_test  <- apply(A_test, 2, FUN=function(x) length(which(x[]==-1)))        # in-negative degree
d_out_pos_test <- apply(A_test, 1, FUN=function(x) length(which(x[]==1)))         # out-positive degree
d_out_neg_test <- apply(A_test, 1, FUN=function(x) length(which(x[]==-1)))        # out-negative degree
#----- Add variables to the datasets
training_edges$pos_in_degree    <- d_in_pos_train[training_edges$user]
training_edges$neg_in_degree    <- d_in_neg_train[training_edges$user]
training_edges$pos_out_degree   <- d_out_pos_train[training_edges$user]
training_edges$neg_out_degree   <- d_out_neg_train[training_edges$user]
test_edges$pos_in_degree    <- d_in_pos_test[test_edges$user]
test_edges$neg_in_degree    <- d_in_neg_test[test_edges$user]
test_edges$pos_out_degree   <- d_out_pos_test[test_edges$user]
test_edges$neg_out_degree   <- d_out_neg_test[test_edges$user]
#CHUNK 7: build the model and evaluate it on the test dataset.
# NA the the rows in which vote=0
training_edges[training_edges$vote == 0,] <- NA
test_edges[test_edges$vote == 0,] <- NA
# Change -1 for 0 in vote column in order to use glm
training_edges$vote[training_edges$vote == -1] <- 0
test_edges$vote[test_edges$vote == -1] <- 0
# Fit the model
logistic = glm(vote ~  pos_in_degree+ neg_in_degree + pos_out_degree + neg_out_degree + recomendation_degree , data = training_edges, family = binomial)
# Summarize the model
summary(logistic)
# Make predictions
probabilities <- predict(logistic, test_edges, type="response", family=binomial)
predicted_signs <- ifelse(probabilities > 0.5, 1, 0)
# Model accuracy
accuracy <- mean(na.omit(predicted_signs) == na.omit(test_edges)$vote)
accuracy
# CHUNK 5: create the new training and test datasets.
# Add the new variable "recomendation degree"
dataA2 <- as.data.frame(as.table(as.matrix(A2)))                  #Dataframe from the adyancency matrix to the power 2
colnames(dataA2) <- c("voter", "user", "recomendation_degree")    #Add names to the columns
dataA2$voter <- as.character(dataA2$voter)
dataA2$user <- as.character(dataA2$user)
newVotings <- merge(votings, dataA2 , by=c("voter","user"))       #Merge votings and dataA2 dataset by "voter" and "user"
# Sort dataset by timestamp and get samples
votings_ordered <- newVotings[order(as.Date(newVotings$timestamp)),]
sample_size = floor(0.8*nrow(votings_ordered))
#set.seed(123)
#training_id = sample(seq_len(nrow(votings_ordered)),size = sample_size)
training_id = votings_ordered[1:sample_size]
training_id = votings_ordered[1:sample_size,]
training_edges = votings_ordered[training_id,]
training_id = votings_ordered[1:sample_size+1,]
training_edges = votings_ordered[training_id,]
training_id = seq_len(nrow(votings_ordered[1:sample_size,]))
training_edges = votings_ordered[training_id,]
test_edges     = votings_ordered[-training_id,]
# CHUNK 6: create the new variables based on the knowledge of how votes spread on the network
#------For training dataset
# Transform the dataset into an adjacency matrix
edge_train_list <- training_edges[,c(1,2,4)]                                      # Create the edge list
G_train <- graph.data.frame(edge_train_list, directed=TRUE)                       # Create the graph
A_train <- as_adjacency_matrix(G_train, names=TRUE, sparse=TRUE, attr = "vote")   # Create the adjacency matrix
# Variables
d_in_pos_train  <- apply(A_train, 2, FUN=function(x) length(which(x[]==1)))       # in-positive degree
d_in_neg_train  <- apply(A_train, 2, FUN=function(x) length(which(x[]==-1)))      # in-negative degree
d_out_pos_train <- apply(A_train, 1, FUN=function(x) length(which(x[]==1)))       # out-positive degree
d_out_neg_train <- apply(A_train, 1, FUN=function(x) length(which(x[]==-1)))      # out-negative degree
#------For test dataset
# Transform the dataset into an adjacency matrix
edge_test_list <- test_edges[,c(1,2,4)]                                           # create the edge list
G_test <- graph.data.frame(edge_test_list, directed=TRUE)                         # create the graph
A_test <- as_adjacency_matrix(G_test, names=TRUE, sparse=TRUE, attr = "vote")     # create the adjacency matrix
# Create variables
d_in_pos_test  <- apply(A_test, 2, FUN=function(x) length(which(x[]==1)))         # in-positive degree
d_in_neg_test  <- apply(A_test, 2, FUN=function(x) length(which(x[]==-1)))        # in-negative degree
d_out_pos_test <- apply(A_test, 1, FUN=function(x) length(which(x[]==1)))         # out-positive degree
d_out_neg_test <- apply(A_test, 1, FUN=function(x) length(which(x[]==-1)))        # out-negative degree
#----- Add variables to the datasets
training_edges$pos_in_degree    <- d_in_pos_train[training_edges$user]
training_edges$neg_in_degree    <- d_in_neg_train[training_edges$user]
training_edges$pos_out_degree   <- d_out_pos_train[training_edges$user]
training_edges$neg_out_degree   <- d_out_neg_train[training_edges$user]
test_edges$pos_in_degree    <- d_in_pos_test[test_edges$user]
test_edges$neg_in_degree    <- d_in_neg_test[test_edges$user]
test_edges$pos_out_degree   <- d_out_pos_test[test_edges$user]
test_edges$neg_out_degree   <- d_out_neg_test[test_edges$user]
#CHUNK 7: build the model and evaluate it on the test dataset.
# NA the the rows in which vote=0
training_edges[training_edges$vote == 0,] <- NA
test_edges[test_edges$vote == 0,] <- NA
# Change -1 for 0 in vote column in order to use glm
training_edges$vote[training_edges$vote == -1] <- 0
test_edges$vote[test_edges$vote == -1] <- 0
# Fit the model
logistic = glm(vote ~  pos_in_degree+ neg_in_degree + pos_out_degree + neg_out_degree + recomendation_degree , data = training_edges, family = binomial)
# Summarize the model
summary(logistic)
# Make predictions
probabilities <- predict(logistic, test_edges, type="response", family=binomial)
predicted_signs <- ifelse(probabilities > 0.5, 1, 0)
# Model accuracy
accuracy <- mean(na.omit(predicted_signs) == na.omit(test_edges)$vote)
accuracy
# load raw data files
votings<-read.table("votings.txt",sep=";",stringsAsFactors = F,header=F,quote="")
# setting headers
colnames(votings)<-c("voter","user","timestamp","vote")
head(votings)
#check_unique <- unique(votings)
# Load libraries
library(igraph)
library(Matrix)
# CHUNK 1: code to split the original datasets in two training_edges and test_edges
sample_size = floor(0.8*nrow(votings))  # Sample size (i.e. 80% of the number of rows in the dataset)
set.seed(123)                           # Set seed to have the same random numbers generated
training_id = sample(seq_len(nrow(votings)),size = sample_size)  # Choose randomly the rows equal to sample_size from all the rows of voting dataset and stores the row number in training_id
training_edges = votings[training_id,]   # Create the training dataset with row numbers stored in training_ind
test_edges     = votings[-training_id,]  # Create the test dataset excluding the row numbers mentioned in training_ind
# CHUNK 2: code to create these variables for the edges.
#------For training dataset
# Transform the dataset into an adjacency matrix
edge_train_list <- training_edges[,c(1,2,4)]                                      # Create the edge list without timestamp
G_train <- graph.data.frame(edge_train_list, directed=TRUE)                       # Create the graph
A_train <- as_adjacency_matrix(G_train, names=TRUE, sparse=TRUE, attr = "vote")   # Create the adjacency matrix
# Duda: ¿Cómo se tienen en cuenta los votos repetidos en la matriz de adyacencia? ¿Coge el último voto? ¿Suma los votos?
# Variables
d_in_pos_train  <- apply(A_train, 2, FUN=function(x) length(which(x[]==1)))    # in-positive degree
d_in_neg_train  <- apply(A_train, 2, FUN=function(x) length(which(x[]==-1)))   # in-negative degree
d_out_pos_train <- apply(A_train, 1, FUN=function(x) length(which(x[]==1)))    # out-positive degree
d_out_neg_train <- apply(A_train, 1, FUN=function(x) length(which(x[]==-1)))   # out-negative degree
total_pos_degree_train = d_in_pos_train + d_out_pos_train                      # Total positive degree
total_neg_degree_train = d_in_neg_train + d_out_neg_train                      # Total negative degree
#------For test dataset
# Transform the dataset into an adjacency matrix
edge_test_list <- test_edges[,c(1,2,4)]                                          # Create the edge list
G_test <- graph.data.frame(edge_test_list, directed=TRUE)                        # Create the graph
A_test <- as_adjacency_matrix(G_test, names=TRUE, sparse=TRUE, attr = "vote")    # Create the adjacency matrix
# Create variables
d_in_pos_test  <- apply(A_test, 2, FUN=function(x) length(which(x[]==1)))      # in-positive degree
d_in_neg_test  <- apply(A_test, 2, FUN=function(x) length(which(x[]==-1)))     # in-negative degree
d_out_pos_test <- apply(A_test, 1, FUN=function(x) length(which(x[]==1)))      # out-positive degree
d_out_neg_test <- apply(A_test, 1, FUN=function(x) length(which(x[]==-1)))     # out-negative degree
total_pos_degree_test = d_in_pos_test + d_out_pos_test                         # Total positive degree
total_neg_degree_test = d_in_neg_test + d_out_neg_test                         # Total negative degree
#----- Add variables to the datasets
training_edges$pos_in_degree    <- d_in_pos_train[training_edges$user]         # Match with user variable.
training_edges$neg_in_degree    <- d_in_neg_train[training_edges$user]
training_edges$pos_out_degree   <- d_out_pos_train[training_edges$user]
training_edges$neg_out_degree   <- d_out_neg_train[training_edges$user]
training_edges$total_pos_degree <- total_pos_degree_train[training_edges$user]
training_edges$total_neg_degree <- total_neg_degree_train[training_edges$user]
test_edges$pos_in_degree    <- d_in_pos_test[test_edges$user]
test_edges$neg_in_degree    <- d_in_neg_test[test_edges$user]
test_edges$pos_out_degree   <- d_out_pos_test[test_edges$user]
test_edges$neg_out_degree   <- d_out_neg_test[test_edges$user]
test_edges$total_pos_degree <- total_pos_degree_test[test_edges$user]
test_edges$total_neg_degree <- total_neg_degree_test[test_edges$user]
# Show heads of the datasets with the new variables
head(training_edges)
head(test_edges)
# CHUNK 3: code to create the regression model and evaluate it on the test.
# NA the the rows in which vote=0
training_edges[training_edges$vote == 0,] <- NA
test_edges[test_edges$vote == 0,] <- NA
# Change -1 for 0 in vote column in order to use glm
training_edges$vote[training_edges$vote == -1] <- 0
test_edges$vote[test_edges$vote == -1] <- 0
# Fit the model
logistic = glm(vote ~  pos_in_degree+ neg_in_degree + pos_out_degree + neg_out_degree , data = training_edges, family = binomial)
# Summarize the model
summary(logistic)
# Make predictions
probabilities   <- predict(logistic, test_edges, type="response", family=binomial)
predicted_signs <- ifelse(probabilities > 0.5, 1, 0)
# Model accuracy
accuracy <- mean(na.omit(predicted_signs) == na.omit(test_edges)$vote)
accuracy
# Entender por qué obtengo NA's en en predicted_signs -> Probabilities contiene NA's porque test_edges los tiene. Por tanto, predicted_signs tiene que contener NA's
# CHUNK 4: create the code and visualizations you consider to evaluate these 3 affirmations
votings0       <- votings[,c(1,2,4)]                                               # votings dataset without timestamp
votings0_graph <- graph.data.frame(votings0, directed=TRUE)                        # Create the graph
A <- as_adjacency_matrix(votings0_graph, names=TRUE, sparse=TRUE, attr = "vote")   # Create the adjacency matrix
A2 <- A %*% A                           # Adyacency matrix to the power two. It gives the preferred vote from u->v according to the vote that the friends and enemies of u have given to v.
C  <- A * 1 * ((sign(A) == sign(A2)))   # Multiply by 1 to transform TRUE->1 and FALSE->0. Element-wise multiplication (A*...) to set zero the 1's obtained because the sign of the correspondings 0's.
same_sign   = nnzero(C)                 # Count the numbers !=0
total_edges = nnzero(A)                 # Count the number of edges !=0 in the adyacency matrix
same_sign / total_edges
# CHUNK 5: create the new training and test datasets.
# Add the new variable "recomendation degree"
dataA2 <- as.data.frame(as.table(as.matrix(A2)))                  #Dataframe from the adyancency matrix to the power 2
colnames(dataA2) <- c("voter", "user", "recomendation_degree")    #Add names to the columns
dataA2$voter <- as.character(dataA2$voter)
dataA2$user <- as.character(dataA2$user)
newVotings <- merge(votings, dataA2 , by=c("voter","user"))       #Merge votings and dataA2 dataset by "voter" and "user"
# Sort dataset by timestamp and get samples
votings_ordered <- newVotings[order(as.Date(newVotings$timestamp)),]
sample_size = floor(0.8*nrow(votings_ordered))
#set.seed(123)
#training_id = sample(seq_len(nrow(votings_ordered)),size = sample_size)
training_id = seq_len(nrow(votings_ordered[1:sample_size,]))
training_edges = votings_ordered[training_id,]
test_edges     = votings_ordered[-training_id,]
# CHUNK 6: create the new variables based on the knowledge of how votes spread on the network
#------For training dataset
# Transform the dataset into an adjacency matrix
edge_train_list <- training_edges[,c(1,2,4)]                                      # Create the edge list
G_train <- graph.data.frame(edge_train_list, directed=TRUE)                       # Create the graph
A_train <- as_adjacency_matrix(G_train, names=TRUE, sparse=TRUE, attr = "vote")   # Create the adjacency matrix
# Variables
d_in_pos_train  <- apply(A_train, 2, FUN=function(x) length(which(x[]==1)))       # in-positive degree
d_in_neg_train  <- apply(A_train, 2, FUN=function(x) length(which(x[]==-1)))      # in-negative degree
d_out_pos_train <- apply(A_train, 1, FUN=function(x) length(which(x[]==1)))       # out-positive degree
d_out_neg_train <- apply(A_train, 1, FUN=function(x) length(which(x[]==-1)))      # out-negative degree
#------For test dataset
# Transform the dataset into an adjacency matrix
edge_test_list <- test_edges[,c(1,2,4)]                                           # create the edge list
G_test <- graph.data.frame(edge_test_list, directed=TRUE)                         # create the graph
A_test <- as_adjacency_matrix(G_test, names=TRUE, sparse=TRUE, attr = "vote")     # create the adjacency matrix
# Create variables
d_in_pos_test  <- apply(A_test, 2, FUN=function(x) length(which(x[]==1)))         # in-positive degree
d_in_neg_test  <- apply(A_test, 2, FUN=function(x) length(which(x[]==-1)))        # in-negative degree
d_out_pos_test <- apply(A_test, 1, FUN=function(x) length(which(x[]==1)))         # out-positive degree
d_out_neg_test <- apply(A_test, 1, FUN=function(x) length(which(x[]==-1)))        # out-negative degree
#----- Add variables to the datasets
training_edges$pos_in_degree    <- d_in_pos_train[training_edges$user]
training_edges$neg_in_degree    <- d_in_neg_train[training_edges$user]
training_edges$pos_out_degree   <- d_out_pos_train[training_edges$user]
training_edges$neg_out_degree   <- d_out_neg_train[training_edges$user]
test_edges$pos_in_degree    <- d_in_pos_test[test_edges$user]
test_edges$neg_in_degree    <- d_in_neg_test[test_edges$user]
test_edges$pos_out_degree   <- d_out_pos_test[test_edges$user]
test_edges$neg_out_degree   <- d_out_neg_test[test_edges$user]
#CHUNK 7: build the model and evaluate it on the test dataset.
# NA the the rows in which vote=0
training_edges[training_edges$vote == 0,] <- NA
test_edges[test_edges$vote == 0,] <- NA
# Change -1 for 0 in vote column in order to use glm
training_edges$vote[training_edges$vote == -1] <- 0
test_edges$vote[test_edges$vote == -1] <- 0
# Fit the model
logistic = glm(vote ~  pos_in_degree+ neg_in_degree + pos_out_degree + neg_out_degree + recomendation_degree , data = training_edges, family = binomial)
# Summarize the model
summary(logistic)
# Make predictions
probabilities <- predict(logistic, test_edges, type="response", family=binomial)
predicted_signs <- ifelse(probabilities > 0.5, 1, 0)
# Model accuracy
accuracy <- mean(na.omit(predicted_signs) == na.omit(test_edges)$vote)
accuracy
a = c(5,7,2,9)
a2 <-ifelse(c >5, 1, 0)
ifelse(a %% 2 == 0,"even","odd")
ifelse(a >5,"even","odd")
install.packages("ISLR")
library(ISLR)
library(ISLR)
help(ISLR)
??ISLR
Auto
Caravan
Carseats
Advertising
plot(cars)
ls
pwd
ruido <- read.csv(file = 'data/ruido_madrid.csv')
ruido <- read.csv(file = './data/ruido_madrid.csv')
ruido <- read.csv(file = './data/datos_ruido_madrid.csv')
head(ruido)
ruido <- read.csv(file = './data/datos_ruido_madrid.csv', header = FALSE, sep = ';')
server <- function(input, output, session) {
}
shinyApp(ui, server))
ruido <- read.csv(file = './data/datos_ruido_madrid.csv', header = FALSE, sep = ';')
head(ruido)
df <- read.csv(file = './data/datos_ruido_madrid.csv', header = FALSE, sep = ';')
head(df)
colnames(df) <- c("Station","Year","Month","Day","Period","LAeq","LAS01","LAS50","LAS90","LAS99")
colnames(df) <- c("Station","Year","Month","Day","Period","LAeq","LAS01","LAS50","LAS90","LAS99")
head(df)
colnames(df) <- c("Station","Year","Month","Day","Period","LAeq","LAS01","LAS10","LAS50","LAS90","LAS99")
head(df)
setwd("~/Documents/ruido_madrid")
df$Date <- df$Year +  df$Month + df$Day
df$Date <- df$Year +  df$Month + df$Day
head(df)
df$Date <- df$Year + str('-/')  + str('-') + df$Month + + str('-') + df$Day
df$Date <- df$Year + str('-/')  + str('-') + df$Month + str('-') + df$Day
df$date <- as.Date(with(df, paste(Year, Month, Day,sep="-")), "%Y-%m-%d")
head(df)
df <- read.csv(file = './data/datos_ruido_madrid.csv', header = FALSE, sep = ';')
colnames(df) <- c("Station","Year","Month","Day","Period","LAeq","LAS01","LAS10","LAS50","LAS90","LAS99")
df$date <- as.Date(with(df, paste(Year, Month, Day,sep="-")), "%Y-%m-%d")
sort(df, )
df <- read.csv(file = './data/datos_ruido_madrid.csv', header = FALSE, sep = ';')
colnames(df) <- c("Station","Year","Month","Day","Period","LAeq","LAS01","LAS10","LAS50","LAS90","LAS99")
df$date <- as.Date(with(df, paste(Year, Month, Day,sep="-")), "%Y-%m-%d")
head(df)
df <- read.csv(file = './data/datos_ruido_madrid.csv', header = FALSE, sep = ';')
colnames(df) <- c("Station","Year","Month","Day","Period","LAeq","LAS01","LAS10","LAS50","LAS90","LAS99")
df$Date <- as.Date(with(df, paste(Year, Month, Day,sep="-")), "%Y-%m-%d")
head(df)
df[order(df$Date),]
head(df)
df <- read.csv(file = './data/datos_ruido_madrid.csv', header = FALSE, sep = ';')
colnames(df) <- c("Station","Year","Month","Day","Period","LAeq","LAS01","LAS10","LAS50","LAS90","LAS99")
df$Date <- as.Date(with(df, paste(Year, Month, Day,sep="-")), "%Y-%m-%d")
df$Year <- NULL
df$Month <- NULL
df$Day <- NULL
df[order(df$Date),]
head(df)
df <- read.csv(file = './data/datos_ruido_madrid.csv', header = FALSE, sep = ';')
colnames(df) <- c("Station","Year","Month","Day","Period","LAeq","LAS01","LAS10","LAS50","LAS90","LAS99")
df$Date <- as.Date(with(df, paste(Year, Month, Day,sep="-")), "%Y-%m-%d")
df$Year <- NULL
df$Month <- NULL
df$Day <- NULL
df[order(df$Date),]
head(df)
df <- read.csv(file = './data/datos_ruido_madrid.csv', header = FALSE, sep = ';')
colnames(df) <- c("Station","Year","Month","Day","Period","LAeq","LAS01","LAS10","LAS50","LAS90","LAS99")
df$Date <- as.Date(with(df, paste(Year, Month, Day,sep="-")), "%Y-%m-%d")
df[,df$Year,df$Month,df$Day] <- NULL
df <- read.csv(file = './data/datos_ruido_madrid.csv', header = FALSE, sep = ';')
colnames(df) <- c("Station","Year","Month","Day","Period","LAeq","LAS01","LAS10","LAS50","LAS90","LAS99")
df$Date <- as.Date(with(df, paste(Year, Month, Day,sep="-")), "%Y-%m-%d")
df[,c(df$Year,df$Month,df$Day)] <- NULL
df <- read.csv(file = './data/datos_ruido_madrid.csv', header = FALSE, sep = ';')
colnames(df) <- c("Station","Year","Month","Day","Period","LAeq","LAS01","LAS10","LAS50","LAS90","LAS99")
df$Date <- as.Date(with(df, paste(Year, Month, Day,sep="-")), "%Y-%m-%d")
df[,c("Year","Month","Day")] <- NULL
df[order(df$Date),]
head(df)
df <- read.csv(file = './data/datos_ruido_madrid.csv', header = FALSE, sep = ';')
colnames(df) <- c("Station","Year","Month","Day","Period","LAeq","LAS01","LAS10","LAS50","LAS90","LAS99")
df$Date <- as.Date(with(df, paste(Year, Month, Day,sep="-")), "%Y-%m-%d")
df[,c("Year","Month","Day")] <- NULL
df <- df[order(df$Date),]
head(df)
data <- read.csv(file = './data/datos_ruido_madrid.csv', header = FALSE, sep = ';')
colnames(df) <- c("Station","Year","Month","Day","Period","LAeq","LAS01","LAS10","LAS50","LAS90","LAS99")
data <- read.csv(file = './data/datos_ruido_madrid.csv', header = FALSE, sep = ';')
colnames(data) <- c("Station","Year","Month","Day","Period","LAeq","LAS01","LAS10","LAS50","LAS90","LAS99")
data$Date <- as.Date(with(df, paste(Year, Month, Day,sep="-")), "%Y-%m-%d")
data <- read.csv(file = './data/datos_ruido_madrid.csv', header = FALSE, sep = ';')
colnames(data) <- c("Station","Year","Month","Day","Period","LAeq","LAS01","LAS10","LAS50","LAS90","LAS99")
data$Date <- as.Date(with(data, paste(Year, Month, Day,sep="-")), "%Y-%m-%d")
# df[,c("Year","Month","Day")] <- NULL
data <- data[order(data$Date),]
head(df)
data <- read.csv(file = './data/datos_ruido_madrid.csv', header = FALSE, sep = ';')
colnames(data) <- c("Station","Year","Month","Day","Period","LAeq","LAS01","LAS10","LAS50","LAS90","LAS99")
data$Date <- as.Date(with(data, paste(Year, Month, Day,sep="-")), "%Y-%m-%d")
# df[,c("Year","Month","Day")] <- NULL
data <- data[order(data$Date),]
head(data)
LAeq_monthly <- data %>%
group_by(Month) %>%
summarise(mean_LAeq = mean(LAeq))
group_by(Data,Month) %>%
group_by(Data,Month)
library("dplyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
group_by(Data,Month)
library("dplyr")
library("dplyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
install.packages("dplyr")
library("dplyr")
